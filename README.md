# Listen, Attend, Spell Model for Speech Recognition & Synthesis

This an individual class project implementing the [Listen, Attend, Spell](https://arxiv.org/abs/1508.01211) model for speech recognition. This machine learning model consists of an encoder, attention module, and decoder. The homework deliverables are as follows:

Implement an attention-based system to solve a sequence-to-sequence problem.

* Setup an encoder
    * Learn the synchrony/rate principles necessary for the encoder
* Setup the (Bidirectional) Pyramidal LSTMs/LSTMCell
* Setup a decoder
* Setup the attention mechanism
* Setup a teacher forcing schedule
* Pad-pack the variable length data
* Explore architectures and hyperparameters for the optimal solution

### Prerequisites

- Python
- PyTorch

### Running

Run each cell in `main.ipynb`